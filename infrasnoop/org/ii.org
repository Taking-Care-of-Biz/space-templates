#+title: Exploring Kubernetes Prow Jobs
#+PROPERTY: header-args:sql-mode+ :product postgres
* Intoduction
Infrasnoop is a work-in-progress db customized for querying kubernetes prow jobs.
This org file acts as a starting template for building out your own explorations into the code.
* Getting started
If you are running this in a coder workspace, then the db is likely already running in the background.  We can test it iwth this code block.
(navigate the cursor to the code block and hit enter to run):

#+begin_src sql-mode
select * from describe_relations();
#+end_src

#+RESULTS:
#+begin_example
 schema |      name      |                         description
--------+----------------+-------------------------------------------------------------
 sigs   | committee      | each committee in the kubernetes sigs.yaml
 sigs   | sig            | each sig in the kubernetes sigs.yaml
 sigs   | user_group     | each usergroup in the kubernetes sigs.yaml
 sigs   | working_group  | each working group in the kubernetes sigs.yaml
 prow   | job_annotation | every annotation of a job take from the prowspec of the job
 prow   | job_label      | every label of a job take from the prowspec of the job
 prow   | job_spec       | the spec from a prowjob.json expanded into sql columns
 prow   | latest_success | The most recent successful build of each job in prow.deck
(8 rows)

#+end_example

This query shows us the tables and views available to us in our two schemas "sigs" and "prow".  Neither of these have data yet, but we can load them up
with these two respective functions

#+begin_src sql-mode :results silent
select * from load_sigs_tables();
#+end_src


#+begin_src sql-mode :results silent
select * from add_prow_deck_jobs();
#+end_src

After running, our app in the background will look at the latest successful runs
and, for each of these jobs, grab their prowjob definition (e.g. their
prowjob.yaml). It takes about a minute to load, but once ready you can look at
the raw data in the table ~prow.job~.

#+begin_src sql-mode
select count(*) from prow.job;
#+end_src

#+RESULTS:
:  count
: -------
:   1507
: (1 row)
:

* Looking at prow jobs further

Let's look at the prow.job table

#+begin_src sql-mode
select * from describe_columns('prow','job');
#+end_src

#+RESULTS:
:   column  |                    description
: ----------+----------------------------------------------------
:  job      | The prow job title. May appear multiple times.
:  build_id | The exact build of this job.
:  data     | the prowjob definition, literally its prowjob.json
: (3 rows)
:

A simple table, with the heart being the data column, which is jsonb.  So any [[https://duckduckgo.com/?t=ffab&q=postgres+operator&ia=web][postgres jsonb operator]] can be used to explore it.

In addition, we've taken some of the relevant parts of the job and turned them into their own views: the spec, the labels, and the annotations.

#+begin_src sql-mode
\d prow.job_spec;
#+end_src

#+RESULTS:
#+begin_example
                    View "prow.job_spec"
      Column       | Type  | Collation | Nullable | Default
-------------------+-------+-----------+----------+---------
 job               | text  |           |          |
 refs              | jsonb |           |          |
 type              | jsonb |           |          |
 agent             | jsonb |           |          |
 report            | jsonb |           |          |
 cluster           | jsonb |           |          |
 context           | jsonb |           |          |
 pod_spec          | jsonb |           |          |
 namespace         | jsonb |           |          |
 rerun_command     | jsonb |           |          |
 prowjob_defaults  | jsonb |           |          |
 decoration_config | jsonb |           |          |

#+end_example

#+begin_src sql-mode
\d prow.job_label;
#+end_src

#+RESULTS:
:               View "prow.job_label"
:  Column  | Type  | Collation | Nullable | Default
: ---------+-------+-----------+----------+---------
:  job     | text  |           |          |
:  label   | text  |           |          |
:  content | jsonb |           |          |
:

#+begin_src sql-mode
\d prow.job_annotation;
#+end_src

#+RESULTS:
:              View "prow.job_annotation"
:    Column   | Type  | Collation | Nullable | Default
: ------------+-------+-----------+----------+---------
:  job        | text  |           |          |
:  annotation | text  |           |          |
:  content    | jsonb |           |          |
:

* Example prow queries
** Jobs without a cluster
#+begin_src sql-mode
select job
  from prow.job
       join prow.job_spec spec using(job)
 where spec.cluster is null;
#+end_src

#+RESULTS:
#+begin_example
                 job
--------------------------------------
 ar-to-s3-sync
 ci-kubernetes-e2e-gci-gce-slow
 e2e-kops-scenario-gcr-mirror
 ci-kubernetes-kind-e2e-parallel
 ci-kubernetes-kind-ipv6-e2e-parallel
 e2e-kops-grid-gcr-mirror-canary
(6 rows)

#+end_example

** Jobs with dind-enabled
#+begin_src sql-mode
select count(job)
  from prow.job_label
 where label = 'preset-dind-enabled';
#+end_src

#+RESULTS:
:  count
: -------
:    619
: (1 row)
:

*** look at all the other labels of these jobs
one way is to use a cte
#+begin_src sql-mode
with dind_jobs as (
  select job
    from prow.job_label
   where label = 'preset-dind-enabled'
)
select job, label, content
  from prow.job j
       join prow.job_label l using(job)
       join dind_jobs d using(job)
 order by j.job, label
 limit 25 ;
#+end_src

#+RESULTS:
#+begin_example
                  job                   |               label               |                content
----------------------------------------+-----------------------------------+----------------------------------------
 build-win-soak-test-cluster            | created-by-prow                   | true
 build-win-soak-test-cluster            | preset-azure-anonymous-pull       | true
 build-win-soak-test-cluster            | preset-azure-cred-only            | true
 build-win-soak-test-cluster            | preset-capz-containerd-1-7-latest | true
 build-win-soak-test-cluster            | preset-dind-enabled               | true
 build-win-soak-test-cluster            | preset-kind-volume-mounts         | true
 build-win-soak-test-cluster            | preset-service-account            | true
 build-win-soak-test-cluster            | prow.k8s.io/build-id              | 1660088051616976896
 build-win-soak-test-cluster            | prow.k8s.io/context               |
 build-win-soak-test-cluster            | prow.k8s.io/id                    | 4ffbf02e-ab86-48cc-97a9-bc26fc843a0b
 build-win-soak-test-cluster            | prow.k8s.io/job                   | build-win-soak-test-cluster
 build-win-soak-test-cluster            | prow.k8s.io/refs.base_ref         | main
 build-win-soak-test-cluster            | prow.k8s.io/refs.org              | kubernetes-sigs
 build-win-soak-test-cluster            | prow.k8s.io/refs.repo             | cluster-api-provider-azure
 build-win-soak-test-cluster            | prow.k8s.io/type                  | periodic
 canary-e2e-gce-cloud-provider-disabled | created-by-prow                   | true
 canary-e2e-gce-cloud-provider-disabled | preset-dind-enabled               | true
 canary-e2e-gce-cloud-provider-disabled | preset-k8s-ssh                    | true
 canary-e2e-gce-cloud-provider-disabled | preset-pull-kubernetes-e2e        | true
 canary-e2e-gce-cloud-provider-disabled | preset-pull-kubernetes-e2e-gce    | true
 canary-e2e-gce-cloud-provider-disabled | preset-service-account            | true
 canary-e2e-gce-cloud-provider-disabled | prow.k8s.io/build-id              | 1661330970315329536
 canary-e2e-gce-cloud-provider-disabled | prow.k8s.io/context               |
 canary-e2e-gce-cloud-provider-disabled | prow.k8s.io/id                    | 7caf8863-2450-4668-92bb-73e6d4e01359
 canary-e2e-gce-cloud-provider-disabled | prow.k8s.io/job                   | canary-e2e-gce-cloud-provider-disabled
(25 rows)

#+end_example

*
* # of jobs with a cluster with dind-enabled and a testgrid-alert-email
This will likely return 0, but here's an example of using postgres native json operators to narrow through the raw data.

#+begin_src sql-mode
select count(distinct job)
  from prow.job
       join prow.job_label label using(job)
       join prow.job_annotation anno using(job)
       join prow.job_spec spec using(job)
 where label = 'preset-dind-enabled'
   and anno.annotation = 'testgrid-alert-email'
   and spec.cluster is not null;
#+end_src

#+RESULTS:
:  count
: -------
:    307
: (1 row)
:

* Jobs without a cluster
An initial query for finding jobs without a cluster is:

#+begin_src sql-mode
select job
  from prow.job
       join prow.job_spec spec using(job)
 where spec.cluster is null
 group by job;
#+end_src

this returns 9 jobs

#+RESULTS:
#+begin_example
                     job
----------------------------------------------
 ar-to-s3-sync
 ci-cos-cgroupv1-containerd-node-e2e-features
 ci-k8s-triage-robot-retriage
 ci-k8s-triage-robot-retriage-important
 ci-kubernetes-csi-1-24-on-kubernetes-master
 e2e-kops-grid-cilium-flatcar-k26-ko26
 pull-kwok-build-main
 pull-kwok-e2e-test-main
 pull-kwok-unit-test-main
(9 rows)

#+end_example

However, this is a bit misleading. They're "spec.cluster" value is null, but it's because there is no spec! We can see this when we try to look at the raw data.

#+begin_src sql-mode
select job, data
  from prow.job
       join prow.job_spec spec using(job)
 where spec.cluster is null;
#+end_src

#+RESULTS:
#+begin_example
                     job                      |                                               data
----------------------------------------------+--------------------------------------------------------------------------------------------------
 ar-to-s3-sync                                | {"ProwJob not found": "prowjobs.prow.k8s.io \"62be6828-9dd9-4046-b340-84aaba81e163\" not found"}
 pull-kwok-e2e-test-main                      | {"ProwJob not found": "prowjobs.prow.k8s.io \"f4878a0b-7eb1-4390-95f9-a1c9139e2da7\" not found"}
 ci-k8s-triage-robot-retriage                 | {"ProwJob not found": "prowjobs.prow.k8s.io \"e9b561f8-a7b0-416f-b51e-0c29b5dd185c\" not found"}
 pull-kwok-unit-test-main                     | {"ProwJob not found": "prowjobs.prow.k8s.io \"21c154af-83be-442f-a656-bcfd78bbeafa\" not found"}
 ci-kubernetes-csi-1-24-on-kubernetes-master  | {"ProwJob not found": "prowjobs.prow.k8s.io \"f8ec28fd-b0b1-4581-8de7-2acc5ad9cbfc\" not found"}
 pull-kwok-build-main                         | {"ProwJob not found": "prowjobs.prow.k8s.io \"0d0c6474-8266-45af-8135-342f6d11fe88\" not found"}
 ci-k8s-triage-robot-retriage-important       | {"ProwJob not found": "prowjobs.prow.k8s.io \"de36f33f-5371-4845-b637-65f8400727df\" not found"}
 ci-cos-cgroupv1-containerd-node-e2e-features | {"ProwJob not found": "prowjobs.prow.k8s.io \"a68711ee-c09a-4e2d-ba5b-c574715e6256\" not found"}
 e2e-kops-grid-cilium-flatcar-k26-ko26        | {"ProwJob not found": "prowjobs.prow.k8s.io \"45f39693-5e73-4aac-a251-8c0dab01a1d3\" not found"}
(9 rows)

#+end_example

This bit of json is being pulled direct from their spyglass link, which we can grab with the below query

#+begin_src sql-mode
select job, url
  from prow.job
       join prow.job_spec spec using(job)
       join prow.deck using(job,build_id)
 where spec.cluster is null;
#+end_src

#+RESULTS:
#+begin_example
                     job                      |                                                                url
----------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------
 ar-to-s3-sync                                | https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ar-to-s3-sync/1661244650901475328
 pull-kwok-e2e-test-main                      | https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/kubernetes-sigs_kwok/607/pull-kwok-e2e-test-main/1661244561256615936
 ci-k8s-triage-robot-retriage                 | https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-k8s-triage-robot-retriage/1661244903008505856
 pull-kwok-unit-test-main                     | https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/kubernetes-sigs_kwok/607/pull-kwok-unit-test-main/1661244561210478592
 ci-kubernetes-csi-1-24-on-kubernetes-master  | https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-kubernetes-csi-1-24-on-kubernetes-master/1661244902685544448
 pull-kwok-build-main                         | https://prow.k8s.io/view/gs/kubernetes-jenkins/pr-logs/pull/kubernetes-sigs_kwok/607/pull-kwok-build-main/1661244561168535552
 ci-k8s-triage-robot-retriage-important       | https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-k8s-triage-robot-retriage-important/1661244903058837504
 ci-cos-cgroupv1-containerd-node-e2e-features | https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/ci-cos-cgroupv1-containerd-node-e2e-features/1661244902626824192/
 e2e-kops-grid-cilium-flatcar-k26-ko26        | https://prow.k8s.io/view/gs/kubernetes-jenkins/logs/e2e-kops-grid-cilium-flatcar-k26-ko26/1659432996307996672
(9 rows)

#+end_example

And, if we only look at the distinct clusters, we can see that every job either has one defined, or is null, and the null ones are the ones without any prowjob definition.

#+begin_src sql-mode
select cluster, count(*)
  from prow.job_spec
 group by cluster
 order by count desc;
#+end_src

#+RESULTS:
#+begin_example
            cluster             | count
--------------------------------+-------
 "default"                      |  1129
 "k8s-infra-prow-build"         |   223
 "k8s-infra-prow-build-trusted" |    93
 "eks-prow-build-cluster"       |    45
 "test-infra-trusted"           |    10
                                |     9
(6 rows)

#+end_example

Is there anything connecting these 9 without prowjobs?

* Footnotes
#+REVEAL_ROOT: https://multiplex.ii.nz
#+NOREVEAL_MULTIPLEX_SECRET: 16830253579594699605
#+NOREVEAL_MULTIPLEX_ID: f0343d4424c81b11
#+OPTIONS: toc:nil
** TODO export via clicking
** setup index.html as default
#+begin_src shell :results silent
# ln -sf ii_client.html index.html
ln -sf ii.html index.html
#+end_src
** start up a webserver
#+name: http.server
#+begin_src tmux :session ":http"
python3 -m http.server
#+end_src
